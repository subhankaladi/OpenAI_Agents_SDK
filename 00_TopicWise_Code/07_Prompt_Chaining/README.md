
# ğŸ§  Notes on Multi-Agent Prompt Chaining System

## ğŸ¯ Goal of the Project:
Build an AI Tutor system using **OpenAI Agents SDK** that:

1. Takes a learning goal from the user (e.g., _â€œI want to learn Pythonâ€_)
2. **Agent 1**: Generates a curriculum outline
3. **Agent 2**: Validates the curriculum for quality and goal alignment
4. **Agent 3**: Writes full lessons based on the curriculum

---

## ğŸ§  Prompt Chaining Concept

Each stepâ€™s output is passed as input to the next agent.  
This is called **Prompt Chaining**.

```
User Input â†’ Agent 1 â†’ Output A
                â†“
            Agent 2 â†’ Validates A
                â†“ (if valid)
            Agent 3 â†’ Uses A to create full lessons
```

---

## ğŸ§ª Behavior of Agent 2

Agent 2 gave:
```json
good_quality: True  
matches_goal: True
```

> â—Even though the input was â€œeyeglasses,â€ the LLM still considered the curriculum logically structured and aligned with a learning goal.

âš ï¸ **Note:** LLMs can sometimes be **confidently wrong**.

---

## âš™ï¸ Agents Overview

### ğŸ”¹ Agent 1: `curriculum_agent`
- **Task**: Generate a step-by-step curriculum
- **Input**: Userâ€™s learning goal
- **Output**: Curriculum as logically ordered text topics

---

### ğŸ”¹ Agent 2: `curriculum_checker_agent`
- **Task**: Validate the curriculum for quality and relevance
- **Input**: Curriculum (from Agent 1)  
- **Note**: Does *not* directly receive the userâ€™s goal

Relies on LLM inference and returns:

```json
{
  good_quality: true/false,
  matches_goal: true/false
}
```

---

### ğŸ”¹ Agent 3: `lesson_writer_agent`
- **Task**: Generate full lessons from the curriculum
- **Input**: Final curriculum output from Agent 1
- **Code**:

```python
# Step 3: Generate Lessons
lessons_result = await Runner.run(
    lesson_writer_agent,
    curriculum_result.final_output,
)
```

**Instructions for Agent 3**:

> Given a structured curriculum outline, write a detailed coding lesson for each section.  
> For each section:
> - Provide a short explanation  
> - Include 1â€“2 code examples  
> - Add one small practice question

---

## ğŸ§ What went wrong?

- You entered: `"what is eyeglasses"`
- Agent 3 was expecting a **coding** curriculum
- But it received a **non-coding topic**

### ğŸ¤– What did the LLM do?
- Read the instruction: _â€œWrite a detailed coding lessonâ€_
- Got input: Curriculum about **eyeglasses**
- LLM got confused and politely clarified:

> _â€œI interpreted your initial request as wanting a curriculum outline about coding...â€_

---

## ğŸ’¥ Final Insight

- **Agent 2 mistakenly validated** a non-coding topic
- **Agent 3** was built to generate **coding** lessons
- When input didnâ€™t match, Agent 3 tried to **auto-correct** and responded accordingly

---  
